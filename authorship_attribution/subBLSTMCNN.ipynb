{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 10:19:04.539634: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14505944016705443036\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10545899776\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3805931527036973301\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 10:19:06.029172: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-18 10:19:06.031314: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-11-18 10:19:06.070873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 10:19:06.071462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:08:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-11-18 10:19:06.071479: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-18 10:19:06.093739: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-18 10:19:06.093778: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-11-18 10:19:06.095639: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-18 10:19:06.096622: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-18 10:19:06.119555: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-18 10:19:06.122990: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-18 10:19:06.162740: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-18 10:19:06.162892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 10:19:06.163483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 10:19:06.163966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-11-18 10:19:06.164222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-18 10:19:07.112232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-18 10:19:07.112266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-11-18 10:19:07.112272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-11-18 10:19:07.112767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 10:19:07.113307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 10:19:07.113818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 10:19:07.114297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 10057 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5)\n",
      "2021-11-18 10:19:07.115608: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberies\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics\n",
    "from scipy import sparse, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_selection import chi2\n",
    "import chardet\n",
    "from collections import Counter\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.2.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "import seaborn as sns\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "import matplotlib.pyplot as plt\n",
    "# display plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'smart_open'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_768154/928052184.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscikitplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mskplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/parsing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2,  # noqa:F401\n\u001b[0m\u001b[1;32m      5\u001b[0m                             \u001b[0mstrip_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_short\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_numeric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                             \u001b[0mstrip_non_alphanum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_multiple_whitespaces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/parsing/preprocessing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msmart_open\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgensim_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'smart_open'"
     ]
    }
   ],
   "source": [
    "# scikit-sklearn\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss, make_scorer, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder, OneHotEncoder,MultiLabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import gensim\n",
    "import scikitplot.plotters as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.compat.v2.__internal__' has no attribute 'tf2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_768154/1384785600.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# deep learning libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_self_attention\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeqSelfAttention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras_self_attention/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mseq_self_attention\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeqSelfAttention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mseq_weighted_attention\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeqWeightedAttention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mscaled_dot_attention\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mScaledDotProductAttention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mreal_former\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResidualScaledDotProductAttention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras_self_attention/seq_self_attention.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSeqSelfAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras_self_attention/backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mkeras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/initializers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;31m# from ALL_OBJECTS. We make no guarantees as to whether these objects will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m# using their correct version.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m \u001b[0mpopulate_deserializable_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/initializers/__init__.py\u001b[0m in \u001b[0;36mpopulate_deserializable_objects\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0mLOCAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m   \u001b[0mLOCAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGENERATED_WITH_V2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;31m# Compatibility aliases (need to exist in both V1 and V2).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.compat.v2.__internal__' has no attribute 'tf2'"
     ]
    }
   ],
   "source": [
    "# deep learning libraries\n",
    "from tensorflow import keras\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint, Callback,CSVLogger\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import * \n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint, Callback,CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "source_dir ='/home/abbey/abbey/dataset/authorship/movie/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(source_dir + 'Newcleanimbd62.csv', encoding=\"utf-8\")\n",
    "data =  data.sample(len(data), random_state=1)\n",
    "data = data[data['content'].isnull()==False] \n",
    "data.dropna(subset=['content'], inplace=True)\n",
    "data.dropna(subset=['userId'], inplace=True)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.userId.unique()), len(data.content.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "try:\n",
    "    from typing import Dict, Iterable, Callable, List, Any, Iterator\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from tqdm import tqdm\n",
    "import toolz\n",
    "import json\n",
    "\n",
    "DEFAULT_EOW = '__eow'\n",
    "DEFAULT_SOW = '__sow'\n",
    "DEFAULT_UNK = '__unk'\n",
    "DEFAULT_PAD = '__pad'\n",
    "\n",
    "class Encoder:\n",
    "    \"\"\" Encodes white-space separated text using byte-pair encoding.  See https://arxiv.org/abs/1508.07909 for details.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size=8192, pct_bpe=0.2, word_tokenizer=None,\n",
    "                 silent=True, ngram_min=2, ngram_max=2, required_tokens=None, strict=False, \n",
    "                 EOW=DEFAULT_EOW, SOW=DEFAULT_SOW, UNK=DEFAULT_UNK, PAD=DEFAULT_PAD):\n",
    "        if vocab_size < 1:\n",
    "            raise ValueError('vocab size must be greater than 0.')\n",
    "\n",
    "        self.EOW = EOW\n",
    "        self.SOW = SOW\n",
    "        self.eow_len = len(EOW)\n",
    "        self.sow_len = len(SOW)\n",
    "        self.UNK = UNK\n",
    "        self.PAD = PAD\n",
    "        self.required_tokens = list(set(required_tokens or []).union({self.UNK, self.PAD}))\n",
    "        self.vocab_size = vocab_size\n",
    "        self.pct_bpe = pct_bpe\n",
    "        self.word_vocab_size = max([int(vocab_size * (1 - pct_bpe)), len(self.required_tokens or [])])\n",
    "        self.bpe_vocab_size = vocab_size - self.word_vocab_size\n",
    "        self.word_tokenizer = word_tokenizer if word_tokenizer is not None else wordpunct_tokenize\n",
    "        self.custom_tokenizer = word_tokenizer is not None\n",
    "        self.word_vocab = {}  # type: Dict[str, int]\n",
    "        self.bpe_vocab = {}  # type: Dict[str, int]\n",
    "        self.inverse_word_vocab = {}  # type: Dict[int, str]\n",
    "        self.inverse_bpe_vocab = {}  # type: Dict[int, str]\n",
    "        self._progress_bar = iter if silent else tqdm\n",
    "        self.ngram_min = ngram_min\n",
    "        self.ngram_max = ngram_max\n",
    "        self.strict = strict\n",
    "\n",
    "    def mute(self):\n",
    "        \"\"\" Turn on silent mode \"\"\"\n",
    "        self._progress_bar = iter\n",
    "\n",
    "    def unmute(self):\n",
    "        \"\"\" Turn off silent mode \"\"\"\n",
    "        self._progress_bar = tqdm\n",
    "\n",
    "    def byte_pair_counts(self, words):\n",
    "        # type: (Encoder, Iterable[str]) -> Iterable[Counter]\n",
    "        \"\"\" Counts space separated token character pairs:\n",
    "            [('T h i s </w>', 4}] -> {'Th': 4, 'hi': 4, 'is': 4}\n",
    "        \"\"\"\n",
    "        for token, count in self._progress_bar(self.count_tokens(words).items()):\n",
    "            bp_counts = Counter()  # type: Counter\n",
    "            for ngram in token.split(' '):\n",
    "                bp_counts[ngram] += count\n",
    "            for ngram_size in range(self.ngram_min, min([self.ngram_max, len(token)]) + 1):\n",
    "                ngrams = [''.join(ngram) for ngram in toolz.sliding_window(ngram_size, token.split(' '))]\n",
    "\n",
    "                for ngram in ngrams:\n",
    "                    bp_counts[''.join(ngram)] += count\n",
    "\n",
    "            yield bp_counts\n",
    "\n",
    "    def count_tokens(self, words):\n",
    "        # type: (Encoder, Iterable[str]) -> Dict[str, int]\n",
    "        \"\"\" Count tokens into a BPE vocab \"\"\"\n",
    "        token_counts = Counter(self._progress_bar(words))\n",
    "        return {' '.join(token): count for token, count in token_counts.items()}\n",
    "\n",
    "    def learn_word_vocab(self, sentences):\n",
    "        # type: (Encoder, Iterable[str]) -> Dict[str, int]\n",
    "        \"\"\" Build vocab from self.word_vocab_size most common tokens in provided sentences \"\"\"\n",
    "        word_counts = Counter(word for word in toolz.concat(map(self.word_tokenizer, sentences)))\n",
    "        for token in set(self.required_tokens or []):\n",
    "            word_counts[token] = int(2**63)\n",
    "        sorted_word_counts = sorted(word_counts.items(), key=lambda p: -p[1])\n",
    "        return {word: idx for idx, (word, count) in enumerate(sorted_word_counts[:self.word_vocab_size])}\n",
    "\n",
    "    def learn_bpe_vocab(self, words):\n",
    "        # type: (Encoder, Iterable[str]) -> Dict[str, int]\n",
    "        \"\"\" Learns a vocab of byte pair encodings \"\"\"\n",
    "        vocab = Counter()  # type: Counter\n",
    "        for token in {self.SOW, self.EOW}:\n",
    "            vocab[token] = int(2**63)\n",
    "        for idx, byte_pair_count in enumerate(self.byte_pair_counts(words)):\n",
    "            for byte_pair, count in byte_pair_count.items():\n",
    "                vocab[byte_pair] += count\n",
    "\n",
    "            if (idx + 1) % 10000 == 0:\n",
    "                self.trim_vocab(10 * self.bpe_vocab_size, vocab)\n",
    "\n",
    "        sorted_bpe_counts = sorted(vocab.items(), key=lambda p: -p[1])[:self.bpe_vocab_size]\n",
    "        return {bp: idx + self.word_vocab_size for idx, (bp, count) in enumerate(sorted_bpe_counts)}\n",
    "\n",
    "    def fit(self, text):\n",
    "        # type: (Encoder, Iterable[str]) -> None\n",
    "        \"\"\" Learn vocab from text. \"\"\"\n",
    "        _text = [l.lower().strip() for l in text]\n",
    "\n",
    "        # First, learn word vocab\n",
    "        self.word_vocab = self.learn_word_vocab(_text)\n",
    "\n",
    "        remaining_words = [word for word in toolz.concat(map(self.word_tokenizer, _text))\n",
    "                           if word not in self.word_vocab]\n",
    "        self.bpe_vocab = self.learn_bpe_vocab(remaining_words)\n",
    "\n",
    "        self.inverse_word_vocab = {idx: token for token, idx in self.word_vocab.items()}\n",
    "        self.inverse_bpe_vocab = {idx: token for token, idx in self.bpe_vocab.items()}\n",
    "\n",
    "    @staticmethod\n",
    "    def trim_vocab(n, vocab):\n",
    "        # type: (int, Dict[str, int]) -> None\n",
    "        \"\"\"  Deletes all pairs below 10 * vocab size to prevent memory problems \"\"\"\n",
    "        pair_counts = sorted(vocab.items(), key=lambda p: -p[1])\n",
    "        pairs_to_trim = [pair for pair, count in pair_counts[n:]]\n",
    "        for pair in pairs_to_trim:\n",
    "            del vocab[pair]\n",
    "\n",
    "    def subword_tokenize(self, word):\n",
    "        # type: (Encoder, str) -> List[str]\n",
    "        \"\"\" Tokenizes inside an unknown token using BPE \"\"\"\n",
    "        end_idx = min([len(word), self.ngram_max])\n",
    "        sw_tokens = [self.SOW]\n",
    "        start_idx = 0\n",
    "\n",
    "        while start_idx < len(word):\n",
    "            subword = word[start_idx:end_idx]\n",
    "            if subword in self.bpe_vocab:\n",
    "                sw_tokens.append(subword)\n",
    "                start_idx = end_idx\n",
    "                end_idx = min([len(word), start_idx + self.ngram_max])\n",
    "            elif len(subword) == 1:\n",
    "                sw_tokens.append(self.UNK)\n",
    "                start_idx = end_idx\n",
    "                end_idx = min([len(word), start_idx + self.ngram_max])\n",
    "            else:\n",
    "                end_idx -= 1\n",
    "\n",
    "        sw_tokens.append(self.EOW)\n",
    "        return sw_tokens\n",
    "\n",
    "    def tokenize(self, sentence):\n",
    "        # type: (Encoder, str) -> List[str]\n",
    "        \"\"\" Split a sentence into word and subword tokens \"\"\"\n",
    "        word_tokens = self.word_tokenizer(sentence.lower().strip())\n",
    "\n",
    "        tokens = []\n",
    "        for word_token in word_tokens:\n",
    "            if word_token in self.word_vocab:\n",
    "                tokens.append(word_token)\n",
    "            else:\n",
    "                tokens.extend(self.subword_tokenize(word_token))\n",
    "\n",
    "        return tokens\n",
    "    def transform(self, sentences, reverse=False, fixed_length=None):\n",
    "        # type: (Encoder, Iterable[str], bool, int) -> Iterable[List[int]]\n",
    "        \"\"\" Turns space separated tokens into vocab idxs \"\"\"\n",
    "        direction = -1 if reverse else 1\n",
    "        for sentence in self._progress_bar(sentences):\n",
    "            encoded = []\n",
    "            tokens = list(self.tokenize(sentence.lower().strip()))\n",
    "            for token in tokens:\n",
    "                if token in self.word_vocab:\n",
    "                    encoded.append(self.word_vocab[token])\n",
    "                elif token in self.bpe_vocab:\n",
    "                    encoded.append(self.bpe_vocab[token])\n",
    "                else:\n",
    "                    encoded.append(self.word_vocab[self.UNK])\n",
    "\n",
    "            if fixed_length is not None:\n",
    "                encoded = encoded[:fixed_length]\n",
    "                while len(encoded) < fixed_length:\n",
    "                    encoded.append(self.word_vocab[self.PAD])\n",
    "\n",
    "            yield encoded[::direction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.userId.unique()), len(data.content.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the train and test file\n",
    "# again using the '\\t' separator to create tab-separated-values files\n",
    "train.to_csv(source_dir+ 'train.csv', index=False)\n",
    "test.to_csv(source_dir+'test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths Train/Test: 49578 / 12395\n"
     ]
    }
   ],
   "source": [
    "# Load \n",
    "data_dir ='/home/abbey/abbey/dataset/authorship/movie/'\n",
    "train = pd.read_csv(data_dir + \"train.csv\")\n",
    "test = pd.read_csv(data_dir + \"test.csv\")\n",
    "print(\"Lengths Train/Test: {} / {}\".format(len(train),len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userId</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32538</th>\n",
       "      <td>504332</td>\n",
       "      <td>rogerrbert</td>\n",
       "      <td>The Christmas Tale  takes place somewhere in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18070</th>\n",
       "      <td>484345</td>\n",
       "      <td>theorobertson</td>\n",
       "      <td>It's a well made and constructed movie that en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewId         userId  \\\n",
       "32538    504332     rogerrbert   \n",
       "18070    484345  theorobertson   \n",
       "\n",
       "                                                 content  \n",
       "32538   The Christmas Tale  takes place somewhere in ...  \n",
       "18070  It's a well made and constructed movie that en...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_encoder(encoder,corpus):\n",
    "    start = time.time()\n",
    "    encoder.fit(corpus)\n",
    "    print(\"Encoder trained: \"+str(int(time.time() - start))+\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sentences_train = train[\"content\"].fillna(\"__empty__\").values\n",
    "list_sentences_test = test[\"content\"].fillna(\"__empty__\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder trained: 18s\n"
     ]
    }
   ],
   "source": [
    "vocabulary = 50000\n",
    "encoder = Encoder(vocabulary, ngram_max=10)\n",
    "corpus = list_sentences_train\n",
    "fit_encoder(encoder,corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tokenized_train = list(encoder.transform(list_sentences_train))\n",
    "list_tokenized_test = list(encoder.transform(list_sentences_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49578\n"
     ]
    }
   ],
   "source": [
    "print(len(list_tokenized_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_percentile = 99.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [len(x) for x in list_tokenized_train + list_tokenized_test]\n",
    "max_size = int(np.percentile(sizes,cutout_percentile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1161\n"
     ]
    }
   ],
   "source": [
    "print(max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_tokenized_test)==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40000, 49922, 42279, 40351, 40001, 435, 17, 1878, 22, 1268, 5956, 21, 11, 7309, 5, 2673, 23, 35866, 22, 8484, 10540, 21, 34, 26, 46, 60, 1081, 29, 10235, 7, 41, 10920, 3973, 22, 1645, 369, 21, 3, 63, 944, 11, 2, 71, 7, 104, 35866, 1185, 53, 273, 74, 59, 4834, 63, 52, 11, 164, 9, 101, 56, 12, 4, 4, 4, 40000, 9842, 271, 40001, 3, 670, 15, 443, 74, 353, 31, 4144, 369, 19, 8, 245, 441, 9, 383, 18, 1927, 382, 17, 19, 124, 8, 30, 77, 280, 9, 141, 56, 40000, 49922, 42279, 40351, 40001, 2008, 432, 757, 1643, 70, 15038, 18, 1255, 127, 1158, 80, 11, 1901, 4, 2, 307, 31, 4144, 74, 1645, 369, 11, 725, 723, 9, 39, 415, 29, 2, 2862, 625, 7216, 3, 69, 9, 39, 639, 19, 215, 8, 30, 89, 12, 25, 17, 37, 1544, 114, 2321, 7, 7216, 33, 4102, 4, 1790, 8, 30, 47, 1150, 9, 39, 233, 1741, 2333, 68, 215, 8, 30, 5, 20776, 431, 73, 5, 3672, 54, 162, 68, 567, 816, 7, 63, 595, 46, 127, 2350, 9, 7216, 74, 66, 12, 120, 12, 8, 13, 11, 3902, 6705, 4, 38, 76, 60, 121, 1179, 311, 198, 40000, 49922, 42279, 40351, 40001, 123, 1633, 117, 3845, 74, 12, 648, 117, 96, 1042, 9, 85, 157, 9, 2, 131, 3, 2, 119, 8, 13, 33, 3813, 3, 2, 597, 5759, 3, 12, 46, 81, 848, 3, 12, 8, 13, 881, 74, 12, 189, 37, 658, 147, 35866, 172, 449, 50, 2, 109, 196, 2861, 257, 11, 18923, 73, 1418, 1040, 311, 38, 2, 131, 74, 19, 67, 176, 82, 3034, 40, 155, 2, 658, 14, 641, 53, 9, 12, 11, 5, 17836, 15, 5471, 7, 2, 4591, 488, 108, 2075, 216, 7, 545, 595, 4, 548, 29, 5, 477, 484, 153, 369, 120, 216, 316, 115, 3, 12, 304, 254, 183, 2, 9876, 342, 609, 7, 1731, 14, 12, 11, 4, 47, 11, 32, 177, 7, 18, 28, 58, 5323, 117, 3, 38, 2, 416, 35866, 11, 5, 142, 250, 55, 41, 10920, 74, 41, 96, 4737, 906, 10, 3, 1866, 1253, 50, 35866, 11, 155, 5, 142, 657, 25, 2, 96, 4737, 2070, 565, 2, 174, 671, 68, 67, 361, 1718, 14, 68, 81, 3, 19, 215, 8, 30, 141, 50, 4, 47, 1475, 301, 7, 570, 161, 38, 2, 131, 3, 361, 365, 11, 8516, 3, 9535, 5038, 11, 3874, 7, 3, 361, 172, 5, 6039, 157, 47, 365, 74, 14, 8, 13, 56, 14, 4, 2357, 2, 28, 11, 1276, 74, 19, 8, 179, 103, 259, 3, 47, 8, 13, 81, 1237, 388, 54, 4409, 74, 18, 11, 176, 881, 530, 9, 1239, 157, 4, 2, 197, 397, 8, 30, 565, 92, 25, 111, 208, 40, 253, 904, 14, 4, 40000, 49922, 42279, 40351, 40001, 11, 1097, 1731, 42, 416, 9, 2072, 74, 19, 2302, 254, 525, 7, 12, 3, 19, 124, 8, 30, 141, 127, 2370, 3831, 231, 48, 9, 116, 5, 130, 28, 25, 55, 19, 43, 9, 951, 57, 346, 74, 1353, 70, 239, 12, 12, 8, 13, 853, 23, 117, 9, 602, 5600, 15277, 291, 107, 109, 49, 18, 127, 10085, 4]\n",
      "[40000, 49932, 2155, 40001, 242, 39, 114, 633, 2127, 16708, 28, 4, 49, 2, 106, 7, 24, 143, 3, 12, 8, 13, 10, 15, 209, 15, 354, 6, 36, 7462, 7, 12, 23, 5, 315, 3, 25, 1089, 51, 7, 24, 87, 143, 22, 77, 55, 26, 8, 13, 38, 24, 1956, 3, 58, 27, 147, 6, 97, 40000, 49932, 2155, 40001, 20, 1088, 4313, 6, 18050, 21, 3, 12, 8, 13, 36, 82, 3610, 3, 394, 2720, 9, 2, 5793, 4, 16708, 8, 13, 532, 29, 3022, 6, 15559, 7, 1154, 3, 7, 223, 3, 25, 3282, 26, 8, 13, 263, 63, 623, 9, 39, 5, 26621, 1859, 28, 84, 9690, 218, 3, 134, 16708, 132, 8, 30, 552, 60, 47, 4, 66, 12, 94, 60, 5, 9690, 541, 20, 4139, 768, 12, 128, 39, 188, 23, 5, 4340, 569, 4, 25, 16708, 8, 13, 9996, 33, 2259, 86, 3019, 53, 145, 5027, 6, 5523, 1539, 7, 36, 60, 295, 112, 25, 10696, 200, 22472, 3, 17655, 3, 4617, 3, 538, 138, 581, 15, 2442, 10, 2, 3916, 7063, 7, 3439, 10, 2, 3108, 3, 26, 190, 8, 30, 48, 9, 116, 293, 1004, 4, 2, 88, 1209, 289, 3124, 10, 289, 1999, 16, 169, 16, 11, 3, 10, 202, 3, 5, 1667, 205, 4946, 691, 3, 392, 6, 1243, 4, 10, 13769, 145, 3022, 6, 7017, 6, 1140, 3600, 7, 4770, 22, 19, 4, 839, 4, 2, 16, 19749, 15, 2384, 3, 791, 16, 1449, 3, 613, 1449, 3, 1103, 295, 15, 354, 21, 3, 83, 8, 166, 289, 38, 33585, 9, 5, 1744, 2875, 4, 6, 106, 7, 44, 3, 16708, 132, 8, 30, 189, 213, 95, 820, 3, 1089, 4287, 555, 20, 5, 28, 49, 32608, 3, 10, 3962, 24, 871, 4, 18, 11, 204, 3, 23, 2, 88, 177, 3, 40000, 49932, 2155, 40001, 11, 5, 649, 609, 7, 143, 3, 108, 51, 7, 2, 1539, 6, 185, 260, 6, 2603, 1375, 6, 3, 7, 223, 3, 161, 7, 3094, 1472, 22, 19, 696, 2, 146, 108, 2, 233, 708, 136, 33, 103, 4677, 38, 31, 2, 169, 15, 122, 392, 301, 10, 34589, 6, 3081, 17, 289, 16, 2454, 16, 6, 2, 49, 21, 3, 33, 60, 95, 82, 36, 9, 814, 38, 4, 12, 8, 13, 36, 60, 2, 4690, 3, 58, 11, 10, 6, 7, 406, 1145, 16, 121, 16, 15, 7026, 3, 25, 14, 2, 899, 11, 2228, 6, 3, 18, 11, 1165, 23, 16708, 18, 70, 1149, 3, 12, 8, 13, 225, 5, 647, 13607, 1288, 9, 3505, 270, 2, 40000, 47002, 41035, 44866, 13, 40001, 6, 2816, 4, 738, 38, 90, 427, 15, 182, 3, 111, 768, 3, 6, 111, 37, 638, 1003, 9856, 7, 2, 96, 22, 3132, 3, 63, 16708, 226, 512, 23, 10, 2741, 705, 20, 661, 194, 11, 260, 115, 9, 5, 30, 20, 331, 346, 6, 5, 22454, 1389, 21, 3, 37237, 6, 4844, 33, 1461, 981, 5, 754, 1363, 23, 5, 1805, 9, 793, 3, 6, 37237, 518, 7, 2, 71, 7, 425, 2384, 3, 34, 20, 425, 2069, 6, 6703, 1550, 151, 9, 9320, 6, 378, 196, 15, 70, 10089, 3, 20, 2384, 10, 1807, 8707, 9, 5, 23046, 15, 2, 15, 13448, 15, 11572, 4315, 119, 4, 18, 11, 513, 5, 189, 118, 29, 612, 7, 2, 1445, 20, 100, 6538, 664, 15, 151, 15, 1782, 144, 6, 768, 3, 115, 549, 922, 6, 717, 23, 104, 5648, 6, 3244, 12, 78, 11, 4, 300, 16708, 231, 23, 2154, 10, 9543, 3600, 84, 708, 136, 769, 426, 6, 906, 270, 20, 427, 15, 182, 5491, 84, 55, 563, 6, 16669, 6, 1584, 2973, 12, 8, 13, 17, 1446, 17, 12, 67, 85, 23, 6050, 84, 55, 5, 1563, 745, 11, 38, 5, 1507, 6, 11, 10000, 6, 288, 10, 295, 15, 354, 6, 5, 3081, 3, 26, 8133, 10, 5, 1371, 7, 58, 36, 77, 644, 128, 2281, 20, 5778, 84, 5, 2684, 1516, 20, 425, 2069, 6, 37, 6821, 17, 2, 1197, 11, 818, 10, 962, 642, 15, 1231, 84, 9076, 1062, 240, 29, 42, 70, 9, 70, 7, 154, 133, 3, 51, 6, 51, 42, 2, 11078, 14, 33, 60, 7381, 4, 49, 2330, 2382, 54, 4265, 54, 3, 59, 1068, 3, 1445, 1413, 3, 16708, 8, 13, 40000, 49932, 2155, 40001, 12788, 17, 790, 90, 6, 111, 272, 15, 26805, 315, 4, 12, 8, 13, 72, 14445, 28, 15, 263, 29, 37, 3157, 2531, 84, 348, 42, 2, 198, 236, 9, 2, 5390, 6, 2, 6140, 8710, 5787, 23, 2, 136, 22, 212, 44, 415, 29, 2, 850, 7, 2, 609, 21, 44, 2585, 2, 272, 10, 2, 307, 3, 108, 100, 471, 15, 35, 144, 1679, 53, 82, 59, 23, 5059, 4, 9, 721, 12, 3589, 4386, 2, 257, 84, 12, 8, 13, 49, 2523, 364, 4, 11328, 3553, 15, 5551, 26198, 54, 6988, 1540, 7, 808, 3553, 7972, 4, 6, 3, 23, 117, 3, 12, 8, 13, 32, 7, 2, 106, 25374, 178, 107, 4]\n"
     ]
    }
   ],
   "source": [
    "maxT =  max(list_tokenized_train)\n",
    "print(maxT)\n",
    "maxTs =  max(list_tokenized_test)\n",
    "print(maxTs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "maxT =  max( [max(x) for x in list_tokenized_train]) + 1\n",
    "print(maxT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = max([max(x) for x in list_tokenized_train+list_tokenized_test])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: 50000, Max Entry Size: 1161\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary: {}, Max Entry Size: {}\".format(max_features,max_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(list_tokenized_train, maxlen=max_size)\n",
    "x_test = sequence.pad_sequences(list_tokenized_test, maxlen=max_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotModel(Callback):\n",
    "    def set_params_(self, model_type, checkpoint_path, dataset, \n",
    "                   batch_size, plot_per_batch,\n",
    "                   dictionary_size, max_review_length, \n",
    "                   best_model_monitor, early_stop_monitor):\n",
    "        self.path = checkpoint_path\n",
    "        self.model_type = model_type\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.dictionary_size = dictionary_size\n",
    "        self.max_review_length = max_review_length\n",
    "        self.best_model_monitor = best_model_monitor\n",
    "        self.early_stop_monitor = early_stop_monitor\n",
    "        self.plot_per_batch = plot_per_batch\n",
    "    \n",
    "    def get_monitor_ticks(self):\n",
    "        if self.best_model_monitor == \"val_acc\":\n",
    "            bm_ind = np.argmax(self.val_acc)\n",
    "        else:\n",
    "            bm_ind = np.argmin(self.val_losses)\n",
    "        \n",
    "        if self.early_stop_monitor == \"val_acc\":\n",
    "            es_ind = np.argmax(self.val_acc)\n",
    "        else:\n",
    "            es_ind = np.argmin(self.val_losses)\n",
    "        return [bm_ind, es_ind]\n",
    "    \n",
    "    def plot(self, save):\n",
    "        clear_output(wait=True)\n",
    "        fig = plt.figure()\n",
    "        plt.grid(True)\n",
    "        plt.plot(self.x, self.acc, '--', label=\"acc\")\n",
    "        plt.plot(self.x, self.val_acc, label=\"val_acc\")\n",
    "        plt.plot(self.x, self.losses, '--', label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        bm_ind, es_ind = self.get_monitor_ticks()\n",
    "        plt.axvline(x=self.x[bm_ind],alpha=0.6,color=\"green\", linestyle='--')\n",
    "        plt.axvline(x=self.x[es_ind],alpha=0.6,color=\"red\", linestyle='--')\n",
    "        title = \"{}: accuracy & loss for {} (length:{}, val acc/loss: {:.4f}/{:.4f})\"\n",
    "        title = title.format(self.model_type,self.dataset,self.max_review_length,max(self.val_acc),min(self.val_losses))\n",
    "        plt.title(title)\n",
    "        plt.legend(['acc: train', 'acc: validation','loss: train', 'loss: validation'], loc='upper left')\n",
    "        plt.show()\n",
    "        if save:\n",
    "            fig.savefig(self.path+\"-figure.png\")\n",
    "            \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 1\n",
    "        self.x = [0]\n",
    "        self.acc = [0]\n",
    "        self.val_acc = [0]\n",
    "        self.losses = [1]\n",
    "        self.val_losses = [1]\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if 'acc' in logs  and 'loss' in logs:\n",
    "            self.logs.append(logs)\n",
    "            self.x.append(self.i)\n",
    "            self.acc.append(logs.get('acc'))\n",
    "            self.losses.append(logs.get('loss'))\n",
    "            if \"val_acc\" in logs and \"val_loss\" in logs:\n",
    "                self.val_acc.append(logs.get('val_acc'))\n",
    "                self.val_losses.append(logs.get('val_loss'))\n",
    "            else:\n",
    "                self.val_acc.append(self.val_acc[len(self.val_acc)-1])\n",
    "                self.val_losses.append(self.val_losses[len(self.val_losses)-1])\n",
    "            self.i += 1\n",
    "            self.plot(False)\n",
    "        else:\n",
    "            keys = []\n",
    "            for k in ['acc', 'val_acc', 'loss', 'val_loss']:\n",
    "                if k not in logs:\n",
    "                    keys.append(k)\n",
    "            print((\"Missing parameters\",keys,logs))\n",
    "    \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if batch%self.plot_per_batch != 0:\n",
    "            return\n",
    "        else:\n",
    "            self.on_epoch_end(batch, logs)\n",
    "    \n",
    "    def on_train_end(self, epoch, logs={}):\n",
    "        self.plot(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning model \n",
    "  * LSTM with Byte-pair encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_classes = 60\n",
    "optimizer = 'adam'\n",
    "loss = 'categorical_crossentropy'\n",
    "embed_size = 128\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "es_patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm():\n",
    "    embed_size = 128\n",
    "    inp = Input(shape=(max_size, ))\n",
    "    x = Embedding(max_features, embed_size)(inp)\n",
    "    x = Bidirectional(LSTM(50, return_sequences=True))(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(num_of_classes, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])  \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1161)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 1161, 128)         6400000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 1161, 100)         71600     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                3060      \n",
      "=================================================================\n",
      "Total params: 6,479,710\n",
      "Trainable params: 6,479,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_lstm()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"lstm\"\n",
    "file_path=model_type+\".weights_base.best.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_plots = 200\n",
    "number_of_batches_per_epoch = len(x_train)/batch_size\n",
    "plot_per_batch = int(number_of_batches_per_epoch/(number_of_plots/epochs))\n",
    "if plot_per_batch == 0:\n",
    "    plot_per_batch = 1\n",
    "plot_per_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = PlotModel()\n",
    "plotter.set_params_(model_type, model_type+\"-checkpoint-path\", \"bpe-{}k\".format(int(vocabulary/1000)), \n",
    "                   batch_size, plot_per_batch,\n",
    "                   vocabulary, max_size, \n",
    "                   'val_loss', 'val_loss')\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "earlyStopping = EarlyStopping(monitor=\"val_loss\", mode=\"max\", patience=es_patience)\n",
    "callbacks_list = [plotter, checkpoint, earlyStopping]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
